{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a1cb5d-a421-4153-b193-33b3c090b405",
   "metadata": {},
   "source": [
    "# Pipelines in DVC\n",
    "\n",
    "This chapter focuses on automating ML pipelines using DVC. Learners create a configuration file containing settings and hyperparameters. They also learn about pipeline visualization using directed acyclic graphs and use commands to describe dependencies, commands, and outputs. Execution of DVC pipelines is covered, including local model training and how Git tracks DVC metadata. Additionally, learners explore metrics and plots tracking in DVC, including how to print metrics, create plot files, and compare metrics and plots across different pipeline stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f85487a0-2a28-40dc-852a-a66b9e499cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the DVC.yml if exist\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.remove(\"dvc.yaml\")\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f376ca78-e385-4a3a-a520-aea6429067eb",
   "metadata": {},
   "source": [
    "## 3.1 Code organization and refactoring\n",
    "\n",
    "### YAML Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef17cd64-bea7-4f3f-8624-0590b53fbe5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': {'categorical_columns': ['type of meal',\n",
      "                                     'room type',\n",
      "                                     'market segment type'],\n",
      "             'label_column': 'booking status',\n",
      "             'numerical_columns': ['number of adults',\n",
      "                                   'number of children',\n",
      "                                   'number of weekend nights',\n",
      "                                   'number of week nights',\n",
      "                                   'car parking space',\n",
      "                                   'lead time',\n",
      "                                   'repeated',\n",
      "                                   'P-C',\n",
      "                                   'P-not-C',\n",
      "                                   'average price',\n",
      "                                   'special requests']},\n",
      " 'pipeline': {'rfc': {'max_depth': 5, 'n_estimators': 5, 'random_state': 42}}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Reading the json file\n",
    "with open('ExampleReadYml/case1/params.json') as f:\n",
    "    d = json.load(f)\n",
    "pprint(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c920e3-b5d2-44b0-b6bd-207c66104cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Saving the json file in a yaml format\n",
    "with open('ExampleReadYml/case1/params-example.yaml', 'w', encoding='utf8') as f:\n",
    "    yaml.dump(d, f, default_flow_style=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3f83857-c8fd-453a-9f0f-5e6e5ef587d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params-example.yaml\n",
      "params.json\n"
     ]
    }
   ],
   "source": [
    "!dir .\\ExampleReadYml\\case1 /B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8330f587-1e49-41b6-bbd2-b558c02b6844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': {'categorical_columns': ['type of meal',\n",
      "                                     'room type',\n",
      "                                     'market segment type'],\n",
      "             'label_column': 'booking status',\n",
      "             'numerical_columns': ['number of adults',\n",
      "                                   'number of children',\n",
      "                                   'number of weekend nights',\n",
      "                                   'number of week nights',\n",
      "                                   'car parking space',\n",
      "                                   'lead time',\n",
      "                                   'repeated',\n",
      "                                   'P-C',\n",
      "                                   'P-not-C',\n",
      "                                   'average price',\n",
      "                                   'special requests']},\n",
      " 'pipeline': {'rfc': {'max_depth': 5, 'n_estimators': 5, 'random_state': 42}}}\n"
     ]
    }
   ],
   "source": [
    "# Loading a yaml file\n",
    "with open('ExampleReadYml/case1/params-example.yaml') as f:\n",
    "    p = yaml.safe_load(f)\n",
    "\n",
    "pprint(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d8c023-0823-43ed-a25f-2f36dc1dcfeb",
   "metadata": {},
   "source": [
    "## 3.2 Writing and visualizing DVC pipelines\n",
    "\n",
    "### Adding preprocessing stage\n",
    "\n",
    "We can use the `dvc stage add` command to create a stage in the `dvc.yaml` file. \n",
    "\n",
    "- specifying the name with `-n`,\n",
    "- parameters with `-p`,\n",
    "- dependencies with `-d`,\n",
    "- outputs with `-o`,\n",
    "- and writing the command at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16dd36b1-e2e3-4a9b-bbba-35bd800e7388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added stage 'preprocess' in 'dvc.yaml'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add dvc.yaml\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    }
   ],
   "source": [
    "!dvc stage add --force -n preprocess \\\n",
    "                       -p params.yaml:preprocess \\\n",
    "                       -d raw_data.csv \\\n",
    "                       -d preprocess.py \\\n",
    "                       -o processed_data.csv python preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a8c0de0-efec-41a4-aaec-225b3679fcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stages:\n",
      "  preprocess:\n",
      "    cmd: python preprocess.py\n",
      "    deps:\n",
      "    - preprocess.py\n",
      "    - raw_data.csv\n",
      "    params:\n",
      "    - preprocess\n",
      "    outs:\n",
      "    - processed_data.csv\n"
     ]
    }
   ],
   "source": [
    "!more dvc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8418f2da-24dc-41d1-b332-15039b579f3a",
   "metadata": {},
   "source": [
    "### Visualizing DVC pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e066cea-dbaa-48e3-bfd6-5b04ceada2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+ \n",
      "| preprocess | \n",
      "+------------+ \n"
     ]
    }
   ],
   "source": [
    "# Print DAG on terminal\n",
    "!dvc dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc053883-0bd5-417c-85aa-04d34835eff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+ \n",
      "| preprocess | \n",
      "+------------+ \n"
     ]
    }
   ],
   "source": [
    "# Display DAG up to a certain step\n",
    "!dvc dag preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de708ce8-8b83-4b56-8703-7b9caf4e2150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+ \n",
      "| processed_data.csv | \n",
      "+--------------------+ \n"
     ]
    }
   ],
   "source": [
    "# Display step outputs as nodes\n",
    "!dvc dag --outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "700e0cf9-6e82-46d4-a6c2-3879c4269cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strict digraph  {\n",
      "\"preprocess\";\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!dvc dag --dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609a696f-a9f5-4e74-9806-1eda3a93206a",
   "metadata": {},
   "source": [
    "### Another example - using the ExampleML1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43968e19-d06a-4628-aab0-1bd55c5a20ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc remove preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d043d6f6-c0fa-4ebe-95ba-5ddfc94795d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc stage add --force -q \\\n",
    "                       -n data-preparation \\\n",
    "                       -d ExampleML1/data-raw/booking.csv \\\n",
    "                       -o ExampleML1/data-processed/train_A.csv \\\n",
    "                       -o ExampleML1/data-processed/train_B.csv \\\n",
    "                       -o ExampleML1/data-processed/test.csv \\\n",
    "                       python -m ExampleML1.split_dataset ExampleML1/data-raw/booking.csv \\\n",
    "                                                          ExampleML1/data-processed/train_A.csv \\\n",
    "                                                          ExampleML1/data-processed/train_B.csv \\\n",
    "                                                          ExampleML1/data-processed/test.csv\n",
    "!dvc stage add --force -q \\\n",
    "                       -n model-trainingA \\\n",
    "                       -d ExampleML1/config/params.json \\\n",
    "                       -d ExampleML1/data-processed/train_A.csv \\\n",
    "                       -d ExampleML1/data-processed/test.csv \\\n",
    "                       python -m ExampleML1.model_training ExampleML1/config/params.json \\\n",
    "                                                           ExampleML1/data-processed/train_A.csv \\\n",
    "                                                           ExampleML1/data-processed/test.csv\n",
    "!dvc stage add --force -q \\\n",
    "                       -n model-trainingB \\\n",
    "                       -d ExampleML1/config/params.json \\\n",
    "                       -d ExampleML1/data-processed/train_B.csv \\\n",
    "                       -d ExampleML1/data-processed/test.csv \\\n",
    "                       python -m ExampleML1.model_training ExampleML1/config/params.json \\\n",
    "                                                           ExampleML1/data-processed/train_B.csv \\\n",
    "                                                           ExampleML1/data-processed/test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9276771-ad84-4914-8500-818d474ed06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stages:\n",
      "  data-preparation:\n",
      "    cmd: python -m ExampleML1.split_dataset ExampleML1/data-raw/booking.csv ExampleML1/data-processed/train_A.csv\n",
      "      ExampleML1/data-processed/train_B.csv ExampleML1/data-processed/test.csv\n",
      "    deps:\n",
      "    - ExampleML1/data-raw/booking.csv\n",
      "    outs:\n",
      "    - ExampleML1/data-processed/test.csv\n",
      "    - ExampleML1/data-processed/train_A.csv\n",
      "    - ExampleML1/data-processed/train_B.csv\n",
      "  model-trainingA:\n",
      "    cmd: python -m ExampleML1.model_training ExampleML1/config/params.json ExampleML1/data-processed/train_A.csv\n",
      "      ExampleML1/data-processed/test.csv\n",
      "    deps:\n",
      "    - ExampleML1/config/params.json\n",
      "    - ExampleML1/data-processed/test.csv\n",
      "    - ExampleML1/data-processed/train_A.csv\n",
      "  model-trainingB:\n",
      "    cmd: python -m ExampleML1.model_training ExampleML1/config/params.json ExampleML1/data-processed/train_B.csv\n",
      "      ExampleML1/data-processed/test.csv\n",
      "    deps:\n",
      "    - ExampleML1/config/params.json\n",
      "    - ExampleML1/data-processed/test.csv\n",
      "    - ExampleML1/data-processed/train_B.csv\n"
     ]
    }
   ],
   "source": [
    "!more dvc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72ee0400-84e6-49de-9db9-61cba1321471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  +------------------+                     \n",
      "                  | data-preparation |                     \n",
      "                  +------------------+                     \n",
      "                  ***                ***                   \n",
      "               ***                      ***                \n",
      "             **                            **              \n",
      "+-----------------+                   +-----------------+  \n",
      "| model-trainingA |                   | model-trainingB |  \n",
      "+-----------------+                   +-----------------+  \n"
     ]
    }
   ],
   "source": [
    "# Print DAG on terminal\n",
    "!dvc dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7f2e462-4c5f-44d2-b89e-092520a36374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+ \n",
      "| ExampleML1\\data-processed\\test.csv | \n",
      "+------------------------------------+ \n",
      "+---------------------------------------+  \n",
      "| ExampleML1\\data-processed\\train_A.csv |  \n",
      "+---------------------------------------+  \n",
      "+---------------------------------------+  \n",
      "| ExampleML1\\data-processed\\train_B.csv |  \n",
      "+---------------------------------------+  \n"
     ]
    }
   ],
   "source": [
    "# Display step outputs as nodes\n",
    "!dvc dag --outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b751ba1-a8db-4c98-98b2-4196a32debd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strict digraph  {\n",
      "\"data-preparation\";\n",
      "\"model-trainingA\";\n",
      "\"model-trainingB\";\n",
      "\"data-preparation\" -> \"model-trainingA\";\n",
      "\"data-preparation\" -> \"model-trainingB\";\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!dvc dag --dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891ee7db-c87d-4645-b17a-c704123f518d",
   "metadata": {},
   "source": [
    "### Ex.1 - Designing a DVC pipeline\n",
    "\n",
    "Designing a DVC pipeline, or DAG, is fundamental to leveraging DVC in your machine learning workflows. DAGs allow us to codify inputs, outputs, and execution of a certain step. The outputs of one step can serve as input to one or more steps, thereby naturally setting the right dependencies between steps.\n",
    "\n",
    "In this exercise, you'll work on designing an ML workflow that contains four stages, namely,\n",
    "\n",
    "- Data preprocessing (preprocess_stage)\n",
    "- Data splitting (split_stage)\n",
    "- Model training (train_stage)\n",
    "- Model evaluation (evaluate_stage)\n",
    "\n",
    "We will exclusively work with the dvc stage add commands. Scroll down to the end of the shell script file (dvc_dag_stages_add.sh) if needed.\n",
    "\n",
    "**Instruction:**\n",
    "\n",
    "1. Add `processed_data.csv` as output from `preprocess_stage`.\n",
    "2. Add parameters from the `split` section of the default parameter file to the `split_stage`.\n",
    "3. Add `model.pkl` as one of the dependencies in the `evaluate_stage`.\n",
    "4. Run the bash file by running bash `dvc_dag_stages_add.sh` command on the terminal. Notice how `dvc.yaml` gets populated.\n",
    "\n",
    "```\n",
    "# Preprocess stage - Output is processed_data.csv\n",
    "dvc stage add --force -n preprocess_stage \\\n",
    "                      -p preprocess \\\n",
    "                      -d raw_data.csv \\\n",
    "                      -d preprocess.py \\\n",
    "                      -o processed_data.csv \\\n",
    "                      python3 preprocess.py\n",
    "\n",
    "# Split stage - This stage uses parameters from `split` section of params.yaml\n",
    "dvc stage add --force -n split_stage \\\n",
    "                      -p split \\\n",
    "                      -d processed_data.csv \\\n",
    "                      -d split.py \\\n",
    "                      -o train_data.csv \\\n",
    "                      -o eval_data.csv \\\n",
    "                      python3 split.py\n",
    "\n",
    "# Train stage - This stage generates model.pkl as output\n",
    "dvc stage add --force -n train_stage \\\n",
    "                      -p train \\\n",
    "                      -d train_data.csv \\\n",
    "                      -d train.py \\\n",
    "                      -o model.pkl \\\n",
    "                      python3 train.py\n",
    "\n",
    "# Evaluate stage - This stage uses model.pkl as one of the input\n",
    "dvc stage add --force -n evaluate_stage \\\n",
    "                      -p evaluate \\\n",
    "                      -d eval_data.csv \\\n",
    "                      -d model.pkl \\\n",
    "                      -d evaluate.py \\\n",
    "                      -o metrics.json \\\n",
    "                      python3 evaluate.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fc34f0-2c80-49f9-b687-a42412467096",
   "metadata": {},
   "source": [
    "### Ex.2 - Visualizing a DVC pipeline\n",
    "\n",
    "In this exercise, you will learn to use the dvc dag command with different flags to gain various insights about your project's pipeline. Understanding these flags and their effects on the dvc dag command's output will help you better manage and understand your project's pipeline.\n",
    "\n",
    "Remember, the goal of this exercise is not just to execute the commands but to understand the nuances of the dvc dag command and how different flags alter its output.\n",
    "\n",
    "**Instruction**\n",
    "\n",
    "1. Run the `dvc dag` command without any flags and observe the output.\n",
    "2. Run the `dvc dag` command with the `--outs` flag and compare the output with the previous step.\n",
    "3. Run the `dvc dag` command with a `train` stage as a target and observe how the output changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54ecdda0-70ac-4e8e-9c9d-46812e6ccbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the data to review\n",
    "with open(\"dvc.yaml\", \"w\") as f:\n",
    "    f.write(\n",
    "        'stages:\\n'\n",
    "        '  preprocess:\\n'\n",
    "        '    cmd: python3 preprocess.py\\n'\n",
    "        '    deps:\\n'\n",
    "        '    - preprocess.py\\n'\n",
    "        '    - raw_data.csv\\n'\n",
    "        '    params:\\n'\n",
    "        '    - preprocess\\n'\n",
    "        '    outs:\\n'\n",
    "        '    - processed_data.csv\\n'\n",
    "        '  split:\\n'\n",
    "        '    cmd: python3 split.py\\n'\n",
    "        '    deps:\\n'\n",
    "        '    - processed_data.csv\\n'\n",
    "        '    - split.py\\n'\n",
    "        '    params:\\n'\n",
    "        '    - split\\n'\n",
    "        '    outs:\\n'\n",
    "        '    - eval_data.csv\\n'\n",
    "        '    - train_data.csv\\n'\n",
    "        '  train:\\n'\n",
    "        '    cmd: python3 train.py\\n'\n",
    "        '    deps:\\n'\n",
    "        '    - train.py\\n'\n",
    "        '    - train_data.csv\\n'\n",
    "        '    params:\\n'\n",
    "        '    - train\\n'\n",
    "        '    outs:\\n'\n",
    "        '    - model.pkl\\n'\n",
    "        '  evaluate:\\n'\n",
    "        '    cmd: python3 evaluate.py\\n'\n",
    "        '    deps:\\n'\n",
    "        '    - eval_data.csv\\n'\n",
    "        '    - evaluate.py\\n'\n",
    "        '    - model.pkl\\n'\n",
    "        '    params:\\n'\n",
    "        '    - evaluate\\n'\n",
    "        '    outs:\\n'\n",
    "        '    - metrics.json\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15c0ac27-1301-4edc-b007-678de167f5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       +------------+     \n",
      "       | preprocess |     \n",
      "       +------------+     \n",
      "              *           \n",
      "              *           \n",
      "              *           \n",
      "          +-------+       \n",
      "          | split |       \n",
      "          +-------+       \n",
      "         **        **     \n",
      "       **            *    \n",
      "      *               **  \n",
      "+-------+               * \n",
      "| train |             **  \n",
      "+-------+            *    \n",
      "         **        **     \n",
      "           **    **       \n",
      "             *  *         \n",
      "        +----------+      \n",
      "        | evaluate |      \n",
      "        +----------+      \n"
     ]
    }
   ],
   "source": [
    "!dvc dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94245f84-48d3-4f91-bab2-daf228f4f969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             +--------------------+               \n",
      "             | processed_data.csv |               \n",
      "             +--------------------+               \n",
      "                ***            ***                \n",
      "              **                  ***             \n",
      "            **                       **           \n",
      "+----------------+                     **         \n",
      "| train_data.csv |                      *         \n",
      "+----------------+                      *         \n",
      "         *                              *         \n",
      "         *                              *         \n",
      "         *                              *         \n",
      "  +-----------+                +---------------+  \n",
      "  | model.pkl |                | eval_data.csv |  \n",
      "  +-----------+*               +---------------+  \n",
      "                ***            ***                \n",
      "                   **        **                   \n",
      "                     **    **                     \n",
      "                +--------------+                  \n",
      "                | metrics.json |                  \n",
      "                +--------------+                  \n"
     ]
    }
   ],
   "source": [
    "!dvc dag --outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c18cc155-d2eb-425f-9aa3-0491551694da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+ \n",
      "| preprocess | \n",
      "+------------+ \n",
      "       *       \n",
      "       *       \n",
      "       *       \n",
      "  +-------+    \n",
      "  | split |    \n",
      "  +-------+    \n",
      "       *       \n",
      "       *       \n",
      "       *       \n",
      "  +-------+    \n",
      "  | train |    \n",
      "  +-------+    \n"
     ]
    }
   ],
   "source": [
    "!dvc dag train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555f4e7e-a2a7-45dd-8798-e8e4dd231c03",
   "metadata": {},
   "source": [
    "## 3.3 Executing DVC pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ace923e-c101-4350-bab3-fb7ddc20d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restarting the DVC.yml\n",
    "import os\n",
    "\n",
    "os.remove(\"dvc.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "829bf0ca-a1fa-43e5-8131-ce516adc78a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc stage add --force -q \\\n",
    "                       -n data-preparation \\\n",
    "                       -d ExampleML1/data-raw/booking.csv \\\n",
    "                       -o ExampleML1/data-processed/train_A.csv \\\n",
    "                       -o ExampleML1/data-processed/train_B.csv \\\n",
    "                       -o ExampleML1/data-processed/test.csv \\\n",
    "                       python -m ExampleML1.split_dataset ExampleML1/data-raw/booking.csv \\\n",
    "                                                          ExampleML1/data-processed/train_A.csv \\\n",
    "                                                          ExampleML1/data-processed/train_B.csv \\\n",
    "                                                          ExampleML1/data-processed/test.csv\n",
    "!dvc stage add --force -q \\\n",
    "                       -n model-trainingA \\\n",
    "                       -d ExampleML1/config/params.json \\\n",
    "                       -d ExampleML1/data-processed/train_A.csv \\\n",
    "                       -d ExampleML1/data-processed/test.csv \\\n",
    "                       python -m ExampleML1.model_training ExampleML1/config/params.json \\\n",
    "                                                           ExampleML1/data-processed/train_A.csv \\\n",
    "                                                           ExampleML1/data-processed/test.csv\n",
    "!dvc stage add --force -q \\\n",
    "                       -n model-trainingB \\\n",
    "                       -d ExampleML1/config/params.json \\\n",
    "                       -d ExampleML1/data-processed/train_B.csv \\\n",
    "                       -d ExampleML1/data-processed/test.csv \\\n",
    "                       python -m ExampleML1.model_training ExampleML1/config/params.json \\\n",
    "                                                           ExampleML1/data-processed/train_B.csv \\\n",
    "                                                           ExampleML1/data-processed/test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00324b88-51fa-47d7-8555-91fc4b821f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stages:\n",
      "  data-preparation:\n",
      "    cmd: python -m ExampleML1.split_dataset ExampleML1/data-raw/booking.csv ExampleML1/data-processed/train_A.csv\n",
      "      ExampleML1/data-processed/train_B.csv ExampleML1/data-processed/test.csv\n",
      "    deps:\n",
      "    - ExampleML1/data-raw/booking.csv\n",
      "    outs:\n",
      "    - ExampleML1/data-processed/test.csv\n",
      "    - ExampleML1/data-processed/train_A.csv\n",
      "    - ExampleML1/data-processed/train_B.csv\n",
      "  model-trainingA:\n",
      "    cmd: python -m ExampleML1.model_training ExampleML1/config/params.json ExampleML1/data-processed/train_A.csv\n",
      "      ExampleML1/data-processed/test.csv\n",
      "    deps:\n",
      "    - ExampleML1/config/params.json\n",
      "    - ExampleML1/data-processed/test.csv\n",
      "    - ExampleML1/data-processed/train_A.csv\n",
      "  model-trainingB:\n",
      "    cmd: python -m ExampleML1.model_training ExampleML1/config/params.json ExampleML1/data-processed/train_B.csv\n",
      "      ExampleML1/data-processed/test.csv\n",
      "    deps:\n",
      "    - ExampleML1/config/params.json\n",
      "    - ExampleML1/data-processed/test.csv\n",
      "    - ExampleML1/data-processed/train_B.csv\n"
     ]
    }
   ],
   "source": [
    "!more dvc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55e2349-4417-404e-8ede-9d153ad56c23",
   "metadata": {},
   "source": [
    "### Dry running a pipeline\n",
    "\n",
    "- `!dvc repro` run the experiment\n",
    "- `!dvc repro --dry` shows only the commands that will be executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7534c6f8-4536-4717-b6c7-ecbc48e5a25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running stage 'data-preparation':\n",
      "> python -m ExampleML1.split_dataset ExampleML1/data-raw/booking.csv ExampleML1/data-processed/train_A.csv ExampleML1/data-processed/train_B.csv ExampleML1/data-processed/test.csv\n",
      "\n",
      "Running stage 'model-trainingA':\n",
      "> python -m ExampleML1.model_training ExampleML1/config/params.json ExampleML1/data-processed/train_A.csv ExampleML1/data-processed/test.csv\n",
      "\n",
      "Running stage 'model-trainingB':\n",
      "> python -m ExampleML1.model_training ExampleML1/config/params.json ExampleML1/data-processed/train_B.csv ExampleML1/data-processed/test.csv\n",
      "Use `dvc push` to send your updates to remote storage.\n"
     ]
    }
   ],
   "source": [
    "!dvc repro --dry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ba8425-5e6e-4fc8-8696-7c9436e5c08b",
   "metadata": {},
   "source": [
    "### Reproducing a pipeline\n",
    "\n",
    "- `!dvc repro` run the experiment\n",
    "- `!dvc repro --dry` shows only the commands that will be executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b638d1e-68d7-4a99-9292-4270030a5938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running stage 'data-preparation':\n",
      "> python -m ExampleML1.split_dataset ExampleML1/data-raw/booking.csv ExampleML1/data-processed/train_A.csv ExampleML1/data-processed/train_B.csv ExampleML1/data-processed/test.csv\n",
      "ExampleML1/data-processed/test.csv file created...\n",
      "ExampleML1/data-processed/train_A.csv file created...\n",
      "ExampleML1/data-processed/train_B.csv file created...\n",
      "Completed!\n",
      "Generating lock file 'dvc.lock'\n",
      "Updating lock file 'dvc.lock'\n",
      "\n",
      "Running stage 'model-trainingA':\n",
      "> python -m ExampleML1.model_training ExampleML1/config/params.json ExampleML1/data-processed/train_A.csv ExampleML1/data-processed/test.csv\n",
      "{'Precision': 0.8914, 'Recall': 0.4613, 'F1 Score': 0.608, 'Accuracy': 0.8031}\n",
      "Updating lock file 'dvc.lock'\n",
      "\n",
      "Running stage 'model-trainingB':\n",
      "> python -m ExampleML1.model_training ExampleML1/config/params.json ExampleML1/data-processed/train_B.csv ExampleML1/data-processed/test.csv\n",
      "{'Precision': 0.8421, 'Recall': 0.4908, 'F1 Score': 0.6202, 'Accuracy': 0.801}\n",
      "Updating lock file 'dvc.lock'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add dvc.lock\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "Use `dvc push` to send your updates to remote storage.\n"
     ]
    }
   ],
   "source": [
    "!dvc repro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c06f90-1854-4ab8-a710-febe00020b58",
   "metadata": {},
   "source": [
    "### Reviewing Case in example ML 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1fcf59c-8488-4162-bb61-145a152541b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the params yaml file\n",
    "with open(\"ExampleML2/config/params.yaml\", \"w\") as f:\n",
    "    f.write(\n",
    "        'preprocess:\\n'\n",
    "        '  drop_colnames:\\n'\n",
    "        '    - Date\\n'\n",
    "        '  target_column: RainTomorrow\\n'\n",
    "        '  categorical_features:\\n'\n",
    "        '    - Location\\n'\n",
    "        '    - WindGustDir\\n'\n",
    "        '    - WindDir9am\\n'\n",
    "        '    - WindDir3pm\\n'\n",
    "        '    - RainToday\\n'\n",
    "        'train_and_evaluate:\\n'\n",
    "        '  target_column: RainTomorrow\\n'\n",
    "        '  train_test_split:\\n'\n",
    "        '    test_size: 0.2\\n'\n",
    "        '    random_state: 1993\\n'\n",
    "        '  shuffle: true\\n'\n",
    "        '  shuffle_random_state: 1993\\n'\n",
    "        '  rfc_params:\\n'\n",
    "        '    n_estimators: 2\\n'\n",
    "        '    max_depth: 2\\n'\n",
    "        '    random_state: 42'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56219545-8894-4d93-be68-338098aec304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dvc yaml\n",
    "with open(\"dvc.yaml\", \"w\") as f:\n",
    "    f.write(\n",
    "        'stages:\\n'\n",
    "        '  preprocess:\\n'\n",
    "        '    # Run the data preprocessing script\\n'\n",
    "        '    cmd: python -m ExampleML2.preprocess_dataset ExampleML2/config/params.yaml'\n",
    "                                                        ' ExampleML2/data-raw/weather.csv'\n",
    "                                                        ' ExampleML2/data-processed/weather.csv\\n'\n",
    "        '    deps:\\n'\n",
    "        '    - ExampleML2/preprocess_dataset.py\\n'\n",
    "        '    - ExampleML2/data-raw/weather.csv\\n'\n",
    "        '    - ExampleML2/utils_and_constants.py\\n'\n",
    "        '    params:\\n'\n",
    "        '      - ExampleML2\\config\\params.yaml:\\n'\n",
    "        '        - preprocess\\n'\n",
    "        '    outs:\\n'\n",
    "        '    - ExampleML2/data-processed/weather.csv\\n'\n",
    "        '  train_and_evaluate:\\n'\n",
    "        '    # Run the model training and evaluation script\\n'\n",
    "        '    cmd: python -m ExampleML2.train_and_evaluate ExampleML2/config/params.yaml'\n",
    "                                                        ' ExampleML2/data-processed/weather.csv\\n'\n",
    "        '    deps:\\n'\n",
    "        '    - ExampleML2/metrics_and_plots.py\\n'\n",
    "        '    - ExampleML2/model.py\\n'\n",
    "        '    # Specify the preprocessed dataset as a dependency\\n'\n",
    "        '    - ExampleML2/data-processed/weather.csv\\n'\n",
    "        '    - ExampleML2/train_and_evaluate.py\\n'\n",
    "        '    - ExampleML2/utils_and_constants.py\\n'\n",
    "        '    params:\\n'\n",
    "        '      - ExampleML2\\config\\params.yaml:\\n'\n",
    "        '        - train_and_evaluate\\n'\n",
    "        '    outs:\\n'\n",
    "        '    - ExampleML2/metrics/metrics.json\\n'\n",
    "        '    - ExampleML2/images/confusion_matrix.png\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0026b52f-e624-4b9c-8125-e561d8a4c512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading raw data and processing it...\n",
      "Target encoding categorical columns...\n",
      "Imputing and scaling features...\n",
      "Writing processed dataset to ExampleML2/data-processed/weather.csv...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python -m ExampleML2.preprocess_dataset ExampleML2/config/params.yaml \\\n",
    "                                         ExampleML2/data-raw/weather.csv \\\n",
    "                                         ExampleML2/data-processed/weather.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "514613c6-0a6d-4b77-8af2-2a3b4f605c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and splitting the dataset...\n",
      "Dataset shape: (25000, 22)\n",
      "Train set shape: (20000, 22)\n",
      "Test set shape: (5000, 22)\n",
      "Training and evaluating the model...\n",
      "====================Test Set Metrics==================\n",
      "{\n",
      "  \"accuracy\": 0.9914,\n",
      "  \"precision\": 0.9771,\n",
      "  \"recall\": 0.9849,\n",
      "  \"f1_score\": 0.981\n",
      "}\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "!python -m ExampleML2.train_and_evaluate ExampleML2/config/params.yaml \\\n",
    "                                         ExampleML2/data-processed/weather.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "12a657ed-de4b-456b-a18a-7d1a3c6ad7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stages:\n",
      "  preprocess:\n",
      "    # Run the data preprocessing script\n",
      "    cmd: python -m ExampleML2.preprocess_dataset ExampleML2/config/params.yaml ExampleML2/data-raw/weather.csv ExampleML2/data-processed/weather.csv\n",
      "    deps:\n",
      "    - ExampleML2/preprocess_dataset.py\n",
      "    - ExampleML2/data-raw/weather.csv\n",
      "    - ExampleML2/utils_and_constants.py\n",
      "    params:\n",
      "      - ExampleML2\\config\\params.yaml:\n",
      "        - preprocess\n",
      "    outs:\n",
      "    - ExampleML2/data-processed/weather.csv\n",
      "  train_and_evaluate:\n",
      "    # Run the model training and evaluation script\n",
      "    cmd: python -m ExampleML2.train_and_evaluate ExampleML2/config/params.yaml ExampleML2/data-processed/weather.csv\n",
      "    deps:\n",
      "    - ExampleML2/metrics_and_plots.py\n",
      "    - ExampleML2/model.py\n",
      "    # Specify the preprocessed dataset as a dependency\n",
      "    - ExampleML2/data-processed/weather.csv\n",
      "    - ExampleML2/train_and_evaluate.py\n",
      "    - ExampleML2/utils_and_constants.py\n",
      "    params:\n",
      "      - ExampleML2\\config\\params.yaml:\n",
      "        - train_and_evaluate\n",
      "    outs:\n",
      "    - ExampleML2/metrics/metrics.json\n",
      "    - ExampleML2/images/confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "!more dvc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2bcf503f-368a-4ee3-80c5-5726f2cdb707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess:\n",
      "  drop_colnames:\n",
      "    - Date\n",
      "  target_column: RainTomorrow\n",
      "  categorical_features:\n",
      "    - Location\n",
      "    - WindGustDir\n",
      "    - WindDir9am\n",
      "    - WindDir3pm\n",
      "    - RainToday\n",
      "train_and_evaluate:\n",
      "  target_column: RainTomorrow\n",
      "  train_test_split:\n",
      "    test_size: 0.2\n",
      "    random_state: 1993\n",
      "  shuffle: true\n",
      "  shuffle_random_state: 1993\n",
      "  rfc_params:\n",
      "    n_estimators: 2\n",
      "    max_depth: 2\n",
      "    random_state: 42\n"
     ]
    }
   ],
   "source": [
    "!more ExampleML2\\config\\params.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08569c74-485d-42bd-9ad0-f81af021a242",
   "metadata": {},
   "source": [
    "### Ex.3 - Execute a ML model training pipeline\n",
    "\n",
    "DVC pipelines are used to ensure reproducibility in your project.\n",
    "\n",
    "In this exercise, you will build on the learnings of creating a pipeline in the dvc.yaml file and execute the steps to train a machine-learning model using a structured approach. Your task is to execute different variants of dvc repro command to understand the nuances of it.\n",
    "\n",
    "**Instruction:**\n",
    "\n",
    "1. Execute a dry run of the pipeline. Understand the steps and execution order.\n",
    "2. Execute only the `preprocessing` stage of the pipeline that is specified under preprocess block in `dvc.yaml`. Observe changes to the `dvc.lock` file.\n",
    "3. Execute only the `training/evaluation` stage of the pipeline that is specified under `train_and_evaluate` block in `dvc.yaml`. Observe changes to the `dvc.lock` file.\n",
    "4. Execute the entire DVC pipeline. Notice how the caching in DVC skips the actual execution of the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "781ee7f4-0743-4c43-ada0-8361bc33998d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running stage 'preprocess':\n",
      "> python -m ExampleML2.preprocess_dataset ExampleML2/config/params.yaml ExampleML2/data-raw/weather.csv ExampleML2/data-processed/weather.csv\n",
      "\n",
      "Running stage 'train_and_evaluate':\n",
      "> python -m ExampleML2.train_and_evaluate ExampleML2/config/params.yaml ExampleML2/data-processed/weather.csv\n",
      "Use `dvc push` to send your updates to remote storage.\n"
     ]
    }
   ],
   "source": [
    "# 1. Execute a dry run of the pipeline. Understand the steps and execution order.\n",
    "!dvc repro --dry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "17bbb2a8-c868-4c9e-93af-1b4f2529a29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 'preprocess' is cached - skipping run, checking out outputs\n",
      "Use `dvc push` to send your updates to remote storage.\n"
     ]
    }
   ],
   "source": [
    "# 2. Execute only the preprocessing stage of the pipeline that is specified under preprocess block in dvc.yaml.\n",
    "!dvc repro preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ccda9fc1-7e93-415d-b658-073d631a922d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema: '2.0'\n",
      "stages:\n",
      "  data-preparation:\n",
      "    cmd: python -m ExampleML1.split_dataset ExampleML1/data-raw/booking.csv ExampleML1/data-processed/train_A.csv\n",
      "      ExampleML1/data-processed/train_B.csv ExampleML1/data-processed/test.csv\n",
      "    deps:\n",
      "    - path: ExampleML1/data-raw/booking.csv\n",
      "      hash: md5\n",
      "      md5: 8e30b9da0032c81edebc9f7492dcea14\n",
      "      size: 3241399\n",
      "    outs:\n",
      "    - path: ExampleML1/data-processed/test.csv\n",
      "      hash: md5\n",
      "      md5: 31e6b80f48ac5efcd9a32d71aef19294\n",
      "      size: 584943\n",
      "    - path: ExampleML1/data-processed/train_A.csv\n",
      "      hash: md5\n",
      "      md5: 18e286dd3cd267afc6bbf27539db3887\n",
      "      size: 1169596\n",
      "    - path: ExampleML1/data-processed/train_B.csv\n",
      "      hash: md5\n",
      "      md5: c39a9e7969c1003f0d8d394953c9880c\n",
      "      size: 1169787\n",
      "  model-trainingA:\n",
      "    cmd: python -m ExampleML1.model_training ExampleML1/config/params.json ExampleML1/data-processed/train_A.csv\n",
      "      ExampleML1/data-processed/test.csv\n",
      "    deps:\n",
      "    - path: ExampleML1/config/params.json\n",
      "      hash: md5\n",
      "      md5: 60ba9e66a18b02aa491f449360da7d03\n",
      "      size: 738\n",
      "    - path: ExampleML1/data-processed/test.csv\n",
      "      hash: md5\n",
      "      md5: 31e6b80f48ac5efcd9a32d71aef19294\n",
      "      size: 584943\n",
      "    - path: ExampleML1/data-processed/train_A.csv\n",
      "      hash: md5\n",
      "      md5: 18e286dd3cd267afc6bbf27539db3887\n",
      "      size: 1169596\n",
      "  model-trainingB:\n",
      "    cmd: python -m ExampleML1.model_training ExampleML1/config/params.json ExampleML1/data-processed/train_B.csv\n",
      "      ExampleML1/data-processed/test.csv\n",
      "    deps:\n",
      "    - path: ExampleML1/config/params.json\n",
      "      hash: md5\n",
      "      md5: 60ba9e66a18b02aa491f449360da7d03\n",
      "      size: 738\n",
      "    - path: ExampleML1/data-processed/test.csv\n",
      "      hash: md5\n",
      "      md5: 31e6b80f48ac5efcd9a32d71aef19294\n",
      "      size: 584943\n",
      "    - path: ExampleML1/data-processed/train_B.csv\n",
      "      hash: md5\n",
      "      md5: c39a9e7969c1003f0d8d394953c9880c\n",
      "      size: 1169787\n",
      "  preprocess:\n",
      "    cmd: python -m ExampleML2.preprocess_dataset ExampleML2/config/params.yaml ExampleML2/data-raw/weather.csv\n",
      "      ExampleML2/data-processed/weather.csv\n",
      "    deps:\n",
      "    - path: ExampleML2/data-raw/weather.csv\n",
      "      hash: md5\n",
      "      md5: 8b80f6484630c3b5b0dacaabc37afaf0\n",
      "      size: 2726131\n",
      "    - path: ExampleML2/preprocess_dataset.py\n",
      "      hash: md5\n",
      "      md5: 6c40e1b5b2ec9431f8136cb7ef1685b7\n",
      "      size: 4673\n",
      "    - path: ExampleML2/utils_and_constants.py\n",
      "      hash: md5\n",
      "      md5: 26aa4e35d65cdb33c3656cf4ef7e3f2d\n",
      "      size: 1081\n",
      "    params:\n",
      "      ExampleML2/config/params.yaml:\n",
      "        preprocess:\n",
      "          drop_colnames:\n",
      "          - Date\n",
      "          target_column: RainTomorrow\n",
      "          categorical_features:\n",
      "          - Location\n",
      "          - WindGustDir\n",
      "          - WindDir9am\n",
      "          - WindDir3pm\n",
      "          - RainToday\n",
      "    outs:\n",
      "    - path: ExampleML2/data-processed/weather.csv\n",
      "      hash: md5\n",
      "      md5: 5a799ba072f8399633fbd5b922d7c499\n",
      "      size: 10526986\n",
      "  train_and_evaluate:\n",
      "    cmd: python -m ExampleML2.train_and_evaluate ExampleML2/config/params.yaml ExampleML2/data-processed/weather.csv\n",
      "    deps:\n",
      "    - path: ExampleML2/data-processed/weather.csv\n",
      "      hash: md5\n",
      "      md5: 5a799ba072f8399633fbd5b922d7c499\n",
      "      size: 10526986\n",
      "    - path: ExampleML2/metrics_and_plots.py\n",
      "      hash: md5\n",
      "      md5: d885711aac188a9f76f703e63a80aa13\n",
      "      size: 1840\n",
      "    - path: ExampleML2/model.py\n",
      "      hash: md5\n",
      "      md5: 53724234a149af6a1bf1a7a726ea73f1\n",
      "      size: 1697\n",
      "    - path: ExampleML2/train_and_evaluate.py\n",
      "      hash: md5\n",
      "      md5: a7b6e10784f537664fcbf0b046d018db\n",
      "      size: 2495\n",
      "    - path: ExampleML2/utils_and_constants.py\n",
      "      hash: md5\n",
      "      md5: 26aa4e35d65cdb33c3656cf4ef7e3f2d\n",
      "      size: 1081\n",
      "    params:\n",
      "      ExampleML2/config/params.yaml:\n",
      "        train_and_evaluate:\n",
      "          target_column: RainTomorrow\n",
      "          train_test_split:\n",
      "            test_size: 0.2\n",
      "            random_state: 1993\n",
      "          shuffle: true\n",
      "          shuffle_random_state: 1993\n",
      "          rfc_params:\n",
      "            n_estimators: 3\n",
      "            max_depth: 2\n",
      "            random_state: 42\n",
      "    outs:\n",
      "    - path: ExampleML2/images/confusion_matrix.png\n",
      "      hash: md5\n",
      "      md5: b25076750f4222a48122453ee68ef7f8\n",
      "      size: 17589\n",
      "    - path: ExampleML2/metrics/metrics.json\n",
      "      hash: md5\n",
      "      md5: 90255332bcae6f8e45214fe535dc7d06\n",
      "      size: 76\n"
     ]
    }
   ],
   "source": [
    "# 2. Observe changes to the dvc.lock file.\n",
    "!more dvc.lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f631aa99-1db5-4a1c-be66-115d45f6e27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 'preprocess' is cached - skipping run, checking out outputs\n",
      "\n",
      "Stage 'train_and_evaluate' is cached - skipping run, checking out outputs\n",
      "Updating lock file 'dvc.lock'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add dvc.lock\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "Use `dvc push` to send your updates to remote storage.\n"
     ]
    }
   ],
   "source": [
    "# 3. Execute only the training/evaluation stage of the pipeline that is specified \n",
    "#    under train_and_evaluate block in dvc.yaml.\n",
    "!dvc repro train_and_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e9554213-67ef-4514-ba63-7b029fcf23d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git rm -r --cached ExampleML2/metrics/metrics.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56f57da1-6aca-40ca-8c10-4050a7d65aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema: '2.0'\n",
      "stages:\n",
      "  data-preparation:\n",
      "    cmd: python -m ExampleML1.split_dataset ExampleML1/data-raw/booking.csv ExampleML1/data-processed/train_A.csv\n",
      "      ExampleML1/data-processed/train_B.csv ExampleML1/data-processed/test.csv\n",
      "    deps:\n",
      "    - path: ExampleML1/data-raw/booking.csv\n",
      "      hash: md5\n",
      "      md5: 8e30b9da0032c81edebc9f7492dcea14\n",
      "      size: 3241399\n",
      "    outs:\n",
      "    - path: ExampleML1/data-processed/test.csv\n",
      "      hash: md5\n",
      "      md5: 31e6b80f48ac5efcd9a32d71aef19294\n",
      "      size: 584943\n",
      "    - path: ExampleML1/data-processed/train_A.csv\n",
      "      hash: md5\n",
      "      md5: 18e286dd3cd267afc6bbf27539db3887\n",
      "      size: 1169596\n",
      "    - path: ExampleML1/data-processed/train_B.csv\n",
      "      hash: md5\n",
      "      md5: c39a9e7969c1003f0d8d394953c9880c\n",
      "      size: 1169787\n",
      "  model-trainingA:\n",
      "    cmd: python -m ExampleML1.model_training ExampleML1/config/params.json ExampleML1/data-processed/train_A.csv\n",
      "      ExampleML1/data-processed/test.csv\n",
      "    deps:\n",
      "    - path: ExampleML1/config/params.json\n",
      "      hash: md5\n",
      "      md5: 60ba9e66a18b02aa491f449360da7d03\n",
      "      size: 738\n",
      "    - path: ExampleML1/data-processed/test.csv\n",
      "      hash: md5\n",
      "      md5: 31e6b80f48ac5efcd9a32d71aef19294\n",
      "      size: 584943\n",
      "    - path: ExampleML1/data-processed/train_A.csv\n",
      "      hash: md5\n",
      "      md5: 18e286dd3cd267afc6bbf27539db3887\n",
      "      size: 1169596\n",
      "  model-trainingB:\n",
      "    cmd: python -m ExampleML1.model_training ExampleML1/config/params.json ExampleML1/data-processed/train_B.csv\n",
      "      ExampleML1/data-processed/test.csv\n",
      "    deps:\n",
      "    - path: ExampleML1/config/params.json\n",
      "      hash: md5\n",
      "      md5: 60ba9e66a18b02aa491f449360da7d03\n",
      "      size: 738\n",
      "    - path: ExampleML1/data-processed/test.csv\n",
      "      hash: md5\n",
      "      md5: 31e6b80f48ac5efcd9a32d71aef19294\n",
      "      size: 584943\n",
      "    - path: ExampleML1/data-processed/train_B.csv\n",
      "      hash: md5\n",
      "      md5: c39a9e7969c1003f0d8d394953c9880c\n",
      "      size: 1169787\n",
      "  preprocess:\n",
      "    cmd: python -m ExampleML2.preprocess_dataset ExampleML2/config/params.yaml ExampleML2/data-raw/weather.csv\n",
      "      ExampleML2/data-processed/weather.csv\n",
      "    deps:\n",
      "    - path: ExampleML2/data-raw/weather.csv\n",
      "      hash: md5\n",
      "      md5: 8b80f6484630c3b5b0dacaabc37afaf0\n",
      "      size: 2726131\n",
      "    - path: ExampleML2/preprocess_dataset.py\n",
      "      hash: md5\n",
      "      md5: 6c40e1b5b2ec9431f8136cb7ef1685b7\n",
      "      size: 4673\n",
      "    - path: ExampleML2/utils_and_constants.py\n",
      "      hash: md5\n",
      "      md5: 26aa4e35d65cdb33c3656cf4ef7e3f2d\n",
      "      size: 1081\n",
      "    params:\n",
      "      ExampleML2/config/params.yaml:\n",
      "        preprocess:\n",
      "          drop_colnames:\n",
      "          - Date\n",
      "          target_column: RainTomorrow\n",
      "          categorical_features:\n",
      "          - Location\n",
      "          - WindGustDir\n",
      "          - WindDir9am\n",
      "          - WindDir3pm\n",
      "          - RainToday\n",
      "    outs:\n",
      "    - path: ExampleML2/data-processed/weather.csv\n",
      "      hash: md5\n",
      "      md5: 5a799ba072f8399633fbd5b922d7c499\n",
      "      size: 10526986\n",
      "  train_and_evaluate:\n",
      "    cmd: python -m ExampleML2.train_and_evaluate ExampleML2/config/params.yaml ExampleML2/data-processed/weather.csv\n",
      "    deps:\n",
      "    - path: ExampleML2/data-processed/weather.csv\n",
      "      hash: md5\n",
      "      md5: 5a799ba072f8399633fbd5b922d7c499\n",
      "      size: 10526986\n",
      "    - path: ExampleML2/metrics_and_plots.py\n",
      "      hash: md5\n",
      "      md5: d885711aac188a9f76f703e63a80aa13\n",
      "      size: 1840\n",
      "    - path: ExampleML2/model.py\n",
      "      hash: md5\n",
      "      md5: 53724234a149af6a1bf1a7a726ea73f1\n",
      "      size: 1697\n",
      "    - path: ExampleML2/train_and_evaluate.py\n",
      "      hash: md5\n",
      "      md5: a7b6e10784f537664fcbf0b046d018db\n",
      "      size: 2495\n",
      "    - path: ExampleML2/utils_and_constants.py\n",
      "      hash: md5\n",
      "      md5: 26aa4e35d65cdb33c3656cf4ef7e3f2d\n",
      "      size: 1081\n",
      "    params:\n",
      "      ExampleML2/config/params.yaml:\n",
      "        train_and_evaluate:\n",
      "          target_column: RainTomorrow\n",
      "          train_test_split:\n",
      "            test_size: 0.2\n",
      "            random_state: 1993\n",
      "          shuffle: true\n",
      "          shuffle_random_state: 1993\n",
      "          rfc_params:\n",
      "            n_estimators: 2\n",
      "            max_depth: 2\n",
      "            random_state: 42\n",
      "    outs:\n",
      "    - path: ExampleML2/images/confusion_matrix.png\n",
      "      hash: md5\n",
      "      md5: 73a06de630edd884a6327cc699a2c05e\n",
      "      size: 17445\n",
      "    - path: ExampleML2/metrics/metrics.json\n",
      "      hash: md5\n",
      "      md5: 1309f5092ba8d530648a071216f62452\n",
      "      size: 78\n"
     ]
    }
   ],
   "source": [
    "# 3. Observe changes to the dvc.lock file.\n",
    "!more dvc.lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a36d593f-d257-4154-bfa7-8c6a4134fb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 'preprocess' is cached - skipping run, checking out outputs\n",
      "\n",
      "Stage 'train_and_evaluate' is cached - skipping run, checking out outputs\n",
      "Use `dvc push` to send your updates to remote storage.\n"
     ]
    }
   ],
   "source": [
    "# 4. Execute the entire DVC pipeline. Notice how the caching in DVC skips the actual execution of the steps.\n",
    "!dvc repro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dd1fd4-5bf3-41fa-acbf-338e1363295f",
   "metadata": {},
   "source": [
    "## 3.4 Evaluation: Metrics and plots in DVC\n",
    "\n",
    "### Metrics: changes in dvc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a82c4ab-1f00-4959-b0f9-d19bf710f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the yaml file\n",
    "with open(\"dvc.yaml\", \"w\") as f:\n",
    "    f.write(\n",
    "        'stages:\\n'\n",
    "        '  preprocess:\\n'\n",
    "        '    # Run the data preprocessing script\\n'\n",
    "        '    cmd: python -m ExampleML2.preprocess_dataset ExampleML2/config/params.yaml'\n",
    "                                                        ' ExampleML2/data-raw/weather.csv'\n",
    "                                                        ' ExampleML2/data-processed/weather.csv\\n'\n",
    "        '    deps:\\n'\n",
    "        '    - ExampleML2/preprocess_dataset.py\\n'\n",
    "        '    - ExampleML2/data-raw/weather.csv\\n'\n",
    "        '    - ExampleML2/utils_and_constants.py\\n'\n",
    "        '    params:\\n'\n",
    "        '      - ExampleML2\\config\\params.yaml:\\n'\n",
    "        '        - preprocess\\n'\n",
    "        '    outs:\\n'\n",
    "        '    - ExampleML2/data-processed/weather.csv\\n'\n",
    "        '  train_and_evaluate:\\n'\n",
    "        '    # Run the model training and evaluation script\\n'\n",
    "        '    cmd: python -m ExampleML2.train_and_evaluate ExampleML2/config/params.yaml'\n",
    "                                                        ' ExampleML2/data-processed/weather.csv\\n'\n",
    "        '    deps:\\n'\n",
    "        '    - ExampleML2/metrics_and_plots.py\\n'\n",
    "        '    - ExampleML2/model.py\\n'\n",
    "        '    # Specify the preprocessed dataset as a dependency\\n'\n",
    "        '    - ExampleML2/data-processed/weather.csv\\n'\n",
    "        '    - ExampleML2/train_and_evaluate.py\\n'\n",
    "        '    - ExampleML2/utils_and_constants.py\\n'\n",
    "        '    params:\\n'\n",
    "        '      - ExampleML2\\config\\params.yaml:\\n'\n",
    "        '        - train_and_evaluate\\n'\n",
    "        '    outs:\\n'\n",
    "        '    - ExampleML2/images/confusion_matrix.png\\n'\n",
    "        '    metrics:\\n'\n",
    "        '    - ExampleML2/metrics/metrics.json:\\n'\n",
    "        '        cache: false'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4befe285-4bb1-4987-8444-fa54b9ff1249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the params yaml file\n",
    "with open(\"ExampleML2/config/params.yaml\", \"w\") as f:\n",
    "    f.write(\n",
    "        'preprocess:\\n'\n",
    "        '  drop_colnames:\\n'\n",
    "        '    - Date\\n'\n",
    "        '  target_column: RainTomorrow\\n'\n",
    "        '  categorical_features:\\n'\n",
    "        '    - Location\\n'\n",
    "        '    - WindGustDir\\n'\n",
    "        '    - WindDir9am\\n'\n",
    "        '    - WindDir3pm\\n'\n",
    "        '    - RainToday\\n'\n",
    "        'train_and_evaluate:\\n'\n",
    "        '  target_column: RainTomorrow\\n'\n",
    "        '  train_test_split:\\n'\n",
    "        '    test_size: 0.2\\n'\n",
    "        '    random_state: 1993\\n'\n",
    "        '  shuffle: true\\n'\n",
    "        '  shuffle_random_state: 1993\\n'\n",
    "        '  rfc_params:\\n'\n",
    "        '    n_estimators: 2\\n'\n",
    "        '    max_depth: 2\\n'\n",
    "        '    random_state: 42'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "938950c7-f7e2-4ec1-90a6-529639eaa18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 'preprocess' is cached - skipping run, checking out outputs\n",
      "\n",
      "Stage 'train_and_evaluate' is cached - skipping run, checking out outputs\n",
      "Use `dvc push` to send your updates to remote storage.\n"
     ]
    }
   ],
   "source": [
    "!dvc repro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bacefb-9c85-4498-83d6-b6da5ea4ae9a",
   "metadata": {},
   "source": [
    "### Printing DVC metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d46286d-300a-4857-aea6-4374819f1cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path                             accuracy    f1_score    precision    recall\n",
      "ExampleML2\\metrics\\metrics.json  0.9914      0.981       0.9771       0.9849\n"
     ]
    }
   ],
   "source": [
    "!dvc metrics show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f270751b-ff46-4518-a23d-a072afd4590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add .\n",
    "!git commit -m \"Experiment Run 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a9aafd-549e-4490-8933-2881ae7ae797",
   "metadata": {},
   "source": [
    "### Ex.4 - Tracking DVC Metrics\n",
    "\n",
    "DVC pipelines are employed to guarantee the reproducibility of your project.\n",
    "\n",
    "In this exercise, you will expand on your knowledge of constructing a pipeline in the dvc.yaml file and carry out the steps to train a machine learning model in a systematic manner. Your assignment involves executing various forms of the dvc metrics command to comprehend its subtleties. We have already run the pipeline once and committed the metrics file to Git.\n",
    "\n",
    "**Instruction:**\n",
    "\n",
    "1. Print the current metrics by running appropriate dvc metrics subcommand.\n",
    "2. Change n_estimators to 3 in line 20 of opened `params.yaml` file.\n",
    "3. Execute the DVC pipeline.\n",
    "4. Compare the changed metrics with the previous run using appropriate dvc metrics subcommand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69117416-a9db-4fd3-b490-046a45bd5f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path                             accuracy    f1_score    precision    recall\n",
      "ExampleML2\\metrics\\metrics.json  0.9914      0.981       0.9771       0.9849\n"
     ]
    }
   ],
   "source": [
    "# 1. Print the current metrics by running appropriate dvc metrics subcommand.\n",
    "!dvc metrics show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "57a5e8f3-5fda-4540-bcd9-cfb374cf7c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess:\n",
      "  drop_colnames:\n",
      "    - Date\n",
      "  target_column: RainTomorrow\n",
      "  categorical_features:\n",
      "    - Location\n",
      "    - WindGustDir\n",
      "    - WindDir9am\n",
      "    - WindDir3pm\n",
      "    - RainToday\n",
      "train_and_evaluate:\n",
      "  target_column: RainTomorrow\n",
      "  train_test_split:\n",
      "    test_size: 0.2\n",
      "    random_state: 1993\n",
      "  shuffle: true\n",
      "  shuffle_random_state: 1993\n",
      "  rfc_params:\n",
      "    n_estimators: 2\n",
      "    max_depth: 2\n",
      "    random_state: 42\n"
     ]
    }
   ],
   "source": [
    "# 2. Change n_estimators to 3 in line 20 of opened params.yaml file.\n",
    "!more ExampleML2\\config\\params.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd83cd2a-7527-4617-ba5d-ba631aa931fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the n_estimators value in params.yaml\n",
    "with open(\"ExampleML2/config/params.yaml\", \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "preprocess:\n",
    "  drop_colnames:\n",
    "    - Date\n",
    "  target_column: RainTomorrow\n",
    "  categorical_features:\n",
    "    - Location\n",
    "    - WindGustDir\n",
    "    - WindDir9am\n",
    "    - WindDir3pm\n",
    "    - RainToday\n",
    "train_and_evaluate:\n",
    "  target_column: RainTomorrow\n",
    "  train_test_split:\n",
    "    test_size: 0.2\n",
    "    random_state: 1993\n",
    "  shuffle: true\n",
    "  shuffle_random_state: 1993\n",
    "  rfc_params:\n",
    "    # Change number of estimators to 3\n",
    "    n_estimators: 3\n",
    "    max_depth: 2\n",
    "    random_state: 42\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95a22c49-1aa9-4c52-9ac2-cefe4109b308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 'preprocess' is cached - skipping run, checking out outputs\n",
      "\n",
      "Running stage 'train_and_evaluate':\n",
      "> python -m ExampleML2.train_and_evaluate ExampleML2/config/params.yaml ExampleML2/data-processed/weather.csv\n",
      "Loading and splitting the dataset...\n",
      "Dataset shape: (25000, 22)\n",
      "Train set shape: (20000, 22)\n",
      "Test set shape: (5000, 22)\n",
      "Training and evaluating the model...\n",
      "====================Test Set Metrics==================\n",
      "{\n",
      "  \"accuracy\": 0.9948,\n",
      "  \"precision\": 0.9774,\n",
      "  \"recall\": 1.0,\n",
      "  \"f1_score\": 0.9886\n",
      "}\n",
      "======================================================\n",
      "Updating lock file 'dvc.lock'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add dvc.lock\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "Use `dvc push` to send your updates to remote storage.\n"
     ]
    }
   ],
   "source": [
    "# 3. Execute the DVC pipeline.\n",
    "!dvc repro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72971254-14df-4ca5-8875-435dc1998224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "nothing to commit, working tree clean\n"
     ]
    }
   ],
   "source": [
    "# 4. Compare the changed metrics with the previous run using appropriate dvc metrics subcommand.\n",
    "!git add .\n",
    "!git commit -m \"Tracking metrics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8822760-2148-461f-8483-574e7eb21ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path                             Metric     HEAD    workspace    Change\n",
      "ExampleML2\\metrics\\metrics.json  accuracy   -       0.9948       -\n",
      "ExampleML2\\metrics\\metrics.json  f1_score   -       0.9886       -\n",
      "ExampleML2\\metrics\\metrics.json  precision  -       0.9774       -\n",
      "ExampleML2\\metrics\\metrics.json  recall     -       1.0          -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DVC failed to load some metrics for following revisions: 'HEAD'.\n"
     ]
    }
   ],
   "source": [
    "!dvc metrics diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d156fa67-25a8-4c1a-9703-c55d2d843fab",
   "metadata": {},
   "source": [
    "### Ex.5 - Adding plots to dvc.yaml\n",
    "In this exercise, you are tasked to fill in the dvc.yaml file that outlines a model training process.\n",
    "\n",
    "The files preprocess_dataset.py and train_and_evaluate.py are responsible for data preprocessing and model training/evaluation respectively, using weather.csv from the raw_dataset folder as input. The output of the model training code is the predictions.csv file, which includes the predictions and the actual values from the test dataset, and a metrics.json file that holds structured metrics data. The predictions.csv file will be utilized to create a confusion matrix plot.\n",
    "\n",
    "Ide Exercise Instruction\n",
    "100XP\n",
    "Set the plot target to the output file containing predictions data.\n",
    "Set the plot template to confusion to plot the confusion matrix.\n",
    "Set the correct value for cache key to track plots in Git repository instead of DVC remote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce51f9-d8c9-4ca9-b3b2-9e5aee6387d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba1a93-dac6-4d0d-98a5-01441d2478f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646c0a87-96cf-4b0a-8538-8e978128d5da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6052fce-8f96-4c45-85b5-f9dd6e7d3cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ba981af-ba4d-497e-b4bd-f9637f65d183",
   "metadata": {},
   "source": [
    "---------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
